# 16. obj-detect-api-ex (이미지 OpenAI 해석과정)

- client와 server를 설정해줄 것임

---

- client 부분

```python
from video import Video
import socket
import json
import net
import cv2
import numpy as np
from objdetect import ObjDetectApi, NumpyDecoder

PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'
MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'

api = ObjDetectApi(MODEL_NAME, PATH_TO_LABELS)

HOST = '127.0.0.1'
PORT = 5000

if __name__ == '__main__':
    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
        s.connect((HOST, PORT))
        writer = s.makefile('wb')
        reader = s.makefile('rb')
        with Video(device=0) as v:
            for image in v:
                # jpg 이미지 변환 및 전송
                jpg = Video.to_jpg(image)
                net.send(writer, jpg)

                # 처리 결과 수신
                output_dict = net.receive(reader)[0].decode()
                output_dict = json.loads(output_dict, cls=NumpyDecoder)
                
                labeled_image = api.visualize(image, output_dict)
                cv2.imshow('frame', labeled_image)
                key = cv2.waitKey(1)
                if key == 27: 
                    break
```

- server 부분   (0.5 이상인 것들만 가져와서 해석함 시간단축을 위해서)

```python
import cv2
import net
import json
import numpy as np
from objdetect import ObjDetectApi, NumpyEncoder

PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'
MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'

api = ObjDetectApi(MODEL_NAME, PATH_TO_LABELS)

HOST = '127.0.0.1'
PORT = 5000

# 0.5 이상만 걸러내는게 빠르며 2개(class,box) 각각의 index를 조사해서 가져온다
def filtering(output_dict):
    classes = []
    boxes = []
    scores = []
    for ix, score in enumerate(output_dict['detection_scores']):
        if score > 0.5:
            classes.append(output_dict['detection_classes'][ix])
            boxes.append(output_dict['detection_boxes'][ix])
            scores.append(score)

    return {
        'detection_classes': np.array(classes),
        'detection_boxes': np.array(boxes),
        'detection_scores': np.array(scores)
    }

def detect(frame):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    output_dict = api.inference_image(frame_rgb) 
    output_dict = filtering(output_dict)
    return output_dict

def receiver(client, addr):
    reader = client.makefile('rb')
    writer = client.makefile('wb')
    while True:
        data, data_len = net.receive(reader)
        if not data :
            break
        # jpg decode
        data = np.frombuffer(data, dtype=np.uint8)
        data = cv2.imdecode(data, cv2.IMREAD_COLOR)

        # object detect 
        outut_dict = detect(data) # 0.5 이상만 담긴녀석을 리턴받음

        result = json.dumps(outut_dict, cls=NumpyEncoder)
        net.send(writer, result.encode())

    # 이미지 처리
    print('exit receiver')

print('start server...')
net.server(HOST, PORT, receiver)
```

- 동영상으로 부터 객체 검출

```python
# 동영상으로부터 객체 검출

import cv2
from video import Video
from objdetect import ObjDetectApi

PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'
MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'

api = ObjDetectApi(MODEL_NAME, PATH_TO_LABELS)

def detect(frame):
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    output_dict = api.inference_image(frame_rgb) 
    labeled_image = api.visualize(frame_rgb, output_dict)
    labeled_image = cv2.cvtColor(labeled_image, cv2.COLOR_RGB2BGR)
    cv2.imshow('frame', labeled_image)
    key = cv2.waitKey(1)
    if key == 27: 
        return False
    else:
        return True

import time

# with Video(file ="vtest.avi") as v:  # 해도됨
with Video(device=0) as v:
    for image in v:
        start_time = time.time()        
        if not detect(image): break  # fps( 초당프레임 )계산해보기
        end_time =time.time()
        fps =1/(end_time-start_time)
        print(f'fps:{fps}')
    
```

- 사진으로 부터 객체 검출하기 (과정 다있음)

```python
# 사진에서 객체 검출하기
import cv2
import pathlib
from objdetect import ObjDetectApi

PATH_TO_LABELS = 'data/mscoco_label_map.pbtxt'
MODEL_NAME = 'ssd_mobilenet_v1_coco_2017_11_17'
api = ObjDetectApi(MODEL_NAME, PATH_TO_LABELS)

# 예제 데이터
PATH_TO_TEST_IMAGES_DIR = pathlib.Path('test_images')
TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob("*.jpg")))

print(TEST_IMAGE_PATHS)

# 검출 진행
for image_path in TEST_IMAGE_PATHS:
    image, output_dict = api.inference_file(image_path)
    print(output_dict) #해석하는 dict의 과정을 볼 수있음
    labeled_image = api.visualize(image, output_dict)
    labeled_image = cv2.cvtColor(labeled_image, cv2.COLOR_RGB2BGR)
    cv2.imshow('image', labeled_image) # 실제 구성은 numpy 배열로구성됨
    cv2.waitKey(0)

cv2.destroyAllWindows()
```

