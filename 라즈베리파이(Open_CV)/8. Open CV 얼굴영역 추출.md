# 8. Open CV 얼굴영역 추출

- Haar Cascade 
  - 머신 러닝기반의 오브젝트 검출 알고리즘
  - 비디오 또는 이미지에서 오브젝트 검출
  - 직사각형으로 영역 구성
  - 찾으려는 오브젝트(얼굴)이 포함된 이미지와 없는 이미지를 사용해 Haar Cascade Classifier를 학습
  - 분류기를 사용하여 오브젝트 검출

- conda 라이브러리 C:\Users\rjh76\anaconda3\Lib\site-packages\cv2\data 로 들어가면 haarcascade_frontalface_default.xml이 있는데 복사해서 디렉토리에 붙여넣기

- haarcascade_frontalface_default.xml
  - 얼굴영역 검출 분류기
    - face_classifier = cv2.CascadeClassifier('....xml')  처럼씀
  - 목표 영역 검출하기
    - cascade.detectMultiScale(image, scaleFactor=1.1, minNeighbors=1, minSize=(150,150))
    - 검출된 영역 리스트(x, y, w, h) 리턴

----

- 1개 얼굴 인식하기예제

```python
import cv2
import sys

cascade_file ="haarcascade_frontalface_default.xml"
cascade = cv2.CascadeClassifier(cascade_file)

image_file ="./data/face2.jpg" #  ./data/face1.jpg
image = cv2.imread(image_file)
image_gs =cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

#얼굴 여러개 리스트!
face_list = cascade.detectMultiScale(image_gs,scaleFactor=1.1,minNeighbors=1, minSize=(150,150)) # minSize보다 작게나오는영역 무시

if len(face_list) > 0:
    print(face_list)		# 이 영역 사각형 색상
    color = (0, 0, 255)
    for face in face_list: # 사각 얼굴영역 저장
        x,y,w,h = face
        cv2.rectangle(image, (x,y), (x+w, y+h), color, thickness=8)
    cv2.imwrite("facedetect-output.PNG", image)

else:
    print("no face")
```

- 여러개 얼굴 인식하기

```python
## 얼굴만 모자이츠 처리하는 예제
import cv2
import sys

cascade_file = "haarcascade_frontalface_default.xml"
cascade = cv2.CascadeClassifier(cascade_file)

image_file = "./data/face2.jpg" #  ./data/face1.jpg
output_file = "face2-mosaic.jpg" #  ./face1-mosaic.jpg

image = cv2.imread(image_file)
image_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # 인식 빠르게 하기위해 비교적 작은 gray를 쓴다

cascade = cv2.CascadeClassifier(cascade_file)
face_list = cascade.detectMultiScale(image_gs, scaleFactor=1.1,minNeighbors=1, minSize=(100,100))

if len(face_list) == 0:
    print("no face")
    quit()

# 확인한 부분에 모자이크 처리하기  --> 축소했다가 확대하면 모자이크 처리가 된다.
mosaic_rate = 10

print(face_list)
color = (0, 0, 255)

for (x,y,w,h) in face_list:
        face_img = image[y:y+h, x:x+w] # 얼굴 부분 자르기
        # 자른 이미지를 지정한 배율로 확대/축소하기
        face_img = cv2.resize(face_img, (w//mosaic_rate, h//mosaic_rate))
        # 확대/축소한 그림을 원래 크기로 돌리기
        face_img = cv2.resize(face_img, (w, h), interpolation=cv2.INTER_AREA)
        image[y:y+h, x:x+w] = face_img # 원래 이미지에 붙이기

# 렌더링 결과를 파일에 출력
cv2.imwrite(output_file, image)
```



- 비디오캠 연동해서 얼굴 인식하는 장치 만들기

```python
import cv2
import numpy as np

face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

cap = cv2.VideoCapture(1)

# cap.get(cv2.CAP_PROP_POS_FRAMES)
# cap.get(cv2.CAP_PROP_FRAME_COUNT)
# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) (3)
# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) (4)

if cap.isOpened():
    print('width: {}, height : {}'.format(cap.get(3), cap.get(4)))
else:
    print("No Camera") 

while True:
    ret, frame = cap.read()
    if ret:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #에러의원인 1 :첫번째에 얼굴이 없었다
        # 가장초기 얼굴이없으면 죽어버리게된다.
        # 얼굴 검출
        faces = face_classifier.detectMultiScale(gray,1.3,5)
        for (x,y,w,h) in faces:
            cropped_face = frame[y:y+h, x:x+w].copy()
            cropped_face = cv2.resize(cropped_face, dsize=(300, 300),
                                      interpolation=cv2.INTER_AREA)
            cv2.rectangle(frame, (x,y),(x+w, y+h), (0,0,255), 3)
    
            cv2.imshow('face', cropped_face)
    cv2.imshow('video', frame)

    if cv2.waitKey(1) == 27: break # ESC 키
    else:
        print('error')

cap.release()
cv2.destroyAllWindows()
```



- fullbody.xml을 이용해서 동영상 안의 사람 인식하기

```python
# fullbody를 이용해 동영상의 사람 인식하기
import cv2
import numpy as np

face_classifier = cv2.CascadeClassifier('haarcascade_fullbody.xml')

cap = cv2.VideoCapture('./data/vtest.avi')

# cap.get(cv2.CAP_PROP_POS_FRAMES)
# cap.get(cv2.CAP_PROP_FRAME_COUNT)
# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640) (3)
# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) (4)

if cap.isOpened():  #해상도 체크
    print('width: {}, height : {}'.format(cap.get(3), cap.get(4))) 
else:
    print("No Camera") 

## 속도를 정량화해서 실제 제품에 쓸수있는지 확인해야됨 fps를 확인해야함!!
while True:
    ret, frame = cap.read()
    if ret:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #에러의원인 1 :첫번째에 얼굴이 없었다
        # 가장초기 얼굴이없으면 죽어버리게된다.
        # 얼굴 검출
        bodies = face_classifier.detectMultiScale(gray,1.3,5)
        for (x,y,w,h) in bodies:
            cropped_face = frame[y:y+h, x:x+w].copy()
            cropped_face = cv2.resize(cropped_face, dsize=(300, 300),
                                      interpolation=cv2.INTER_AREA)
            cv2.rectangle(frame, (x,y),(x+w, y+h), (0,0,255), 3)
    
            cv2.imshow('face', cropped_face) # 얘를 들여쓰기해야 초장에 얼굴프레임이 있음.
        #그리고 마지막에 detect된거를 보여줌!왼쪽상단에!
    cv2.imshow('video', frame)

    if cv2.waitKey(1) == 27: break # ESC 키
    else:
        print('error')

cap.release()
cv2.destroyAllWindows()
```

- 라즈베리 파이에서도 적용가능한 카메라로 인식된부분 상단표기

```python
import cv2
from cv2.data import haarcascades
from os import path
from video import Video

face_xml = path.join(haarcascades,'haarcascade_frontalface_default.xml')
face_cascade = cv2.CascadeClassifier(face_xml)

FACE_WIDTH =200

def detect_face(frame):
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces =face_cascade.detectMultiScale(gray, 1.3 , 5)
    for(x,y,w,h) in faces:
        minLength =min(w,h)
        if minLength <150 : break #작은영역무시
        width =max(w,h)

        #얼굴부분 검출
        x= x+w//2 -width//2
        y= y+h//2 -width//2
        face_image =frame[y:y+width, x:x+width].copy()

        #얼굴 영역 표시
        cv2.rectangle(frame,(x,y),(x+width,y+width),(255,0,0),2)
        #얼굴부분만 좌측 상단출력

        # face_image =cv2.resize(face_image,
        #                         dsize=(FACE_WIDTH,FACE_WIDTH),
        #                         interpolation=cv2.INTER_AREA)
        face_image=Video.resize_frame(face_image,FACE_WIDTH,FACE_WIDTH)
        frame[0:FACE_WIDTH, 0:FACE_WIDTH] =face_image[:]
    
    return frame

with Video(device=1) as v:
    for image in v:
        image =detect_face(image)
        #보여주기
        if not Video.show(image):break

cv2.destroyAllWindows()
```



----

## 버튼을 눌렀을때 영상이 재생되고 꺼지는 예제

```python
from gpiozero import Button, LED
from signal import pause
from video import Video
import time
import cv2
import numpy as np

startBtn = Button(16,bounce_time=0.05)
endBtn =Button(21,bounce_time =0.05)
led =LED(20)
video_on = False

empty_image = np.full((480,640,3),(128,128,128),dtype=np.uint8) +255

def start_video():
    global video_on
    print('start')
    video_on =True
    led.on()

def end_video():
    global video_on
    print('end')
    video_on =False
    led.off()

startBtn.when_pressed =start_video
endBtn.when_pressed =end_video

with Video(device=0) as v:
    for image in v:
        if video_on:
            Video.show(image)
        
        else:
            Video.show(empty_image)
```

